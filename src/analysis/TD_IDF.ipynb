{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import Libraries and Download NLTK Data\n",
        "Import required libraries and download NLTK data for tokenization and stopwords."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import math\n",
        "import os\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "from joblib import Parallel, delayed\n",
        "from gensim import corpora, models\n",
        "import pandas as pd\n",
        "from itertools import product\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "# Download required NLTK data\n",
        "nltk_data_path = os.path.expanduser('~/nltk_data')\n",
        "try:\n",
        "    nltk.download('punkt', download_dir=nltk_data_path, quiet=True)\n",
        "    nltk.download('stopwords', download_dir=nltk_data_path, quiet=True)\n",
        "except Exception as e:\n",
        "    print(f\"Error downloading NLTK data: {e}\")\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define Helper Functions\n",
        "Define functions for tokenization, file reading, and custom TF, IDF, and normalization methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tokenization function\n",
        "def tokenize(text):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    if not isinstance(text, str):\n",
        "        text = str(text)\n",
        "    try:\n",
        "        tokens = word_tokenize(text.lower())\n",
        "        return [lemmatizer.lemmatize(token) for token in tokens if token.isalnum() and token not in stop_words]\n",
        "    except Exception as e:\n",
        "        print(f\"Tokenization failed for text: {text[:100]}\\\\nError: {e}\")\n",
        "        return []\n",
        "\n",
        "\n",
        "# File reading function for CSV files\n",
        "def read_csv_files(doc_file, qrel_file, query_file):\n",
        "    try:\n",
        "        doc_df = pd.read_csv(doc_file)\n",
        "        if not {'DocID', 'Text'}.issubset(doc_df.columns):\n",
        "            raise ValueError(\"The document file contains the columns 'DocID' and 'Text'.\")\n",
        "        docs = {int(doc_id): text for doc_id, text in zip(doc_df['DocID'], doc_df['Text'])}\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading the documentes file: {e}\")\n",
        "        docs = {}\n",
        "    try:\n",
        "        qrel_df = pd.read_csv(qrel_file)\n",
        "        if not {'QueryID', 'DocID'}.issubset(qrel_df.columns):\n",
        "            raise ValueError(\"The rels file must contain the columns 'QueryID', 'DocID'.\")\n",
        "        qrels = defaultdict(set)\n",
        "        for _, row in qrel_df.iterrows():\n",
        "            query_id = int(row['QueryID'])\n",
        "            doc_id = int(row['DocID'])\n",
        "            if query_id > 0 and doc_id > 0:\n",
        "                qrels[query_id].add(doc_id)\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading rels file: {e}\")\n",
        "        qrels = defaultdict(set)\n",
        "    try:\n",
        "        query_df = pd.read_csv(query_file)\n",
        "        if not {'QueryID', 'Text'}.issubset(query_df.columns):\n",
        "            raise ValueError(\"The query file must contain the 'QueryID' and 'Text' columns.\")\n",
        "        queries = {int(query_id): text for query_id, text in zip(query_df['QueryID'], query_df['Text'])}\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading query file: {e}\")\n",
        "        queries = {}\n",
        "    return docs, qrels, queries\n",
        "\n",
        "# Load collection from CSV files\n",
        "def load_collection(base_path, dataset_name):\n",
        "    doc_file = f\"{base_path}/{dataset_name}_docs.csv\"\n",
        "    qrel_file = f\"{base_path}/{dataset_name}_qrels.csv\"\n",
        "    query_file = f\"{base_path}/{dataset_name}_queries.csv\"\n",
        "    docs, qrels, queries = read_csv_files(doc_file, qrel_file, query_file)\n",
        "    if not docs or not queries or not qrels:\n",
        "        print(f\"Warning: Incomplete data for {dataset_name}\")\n",
        "    return docs, queries, qrels\n",
        "\n",
        "# Custom TF methods\n",
        "def compute_natural_tf(tokens, dictionary):\n",
        "    bow = dictionary.doc2bow(tokens)\n",
        "    return [(term_id, count) for term_id, count in bow]\n",
        "\n",
        "def compute_augmented_tf(tokens, dictionary):\n",
        "    bow = dictionary.doc2bow(tokens)\n",
        "    max_tf = max([count for _, count in bow], default=1)\n",
        "    return [(term_id, 0.5 + 0.5 * (count / max_tf)) for term_id, count in bow]\n",
        "\n",
        "def compute_boolean_tf(tokens, dictionary):\n",
        "    bow = dictionary.doc2bow(tokens)\n",
        "    return [(term_id, 1) for term_id, _ in bow]\n",
        "\n",
        "def compute_log_avg_tf(tokens, dictionary):\n",
        "    bow = dictionary.doc2bow(tokens)\n",
        "    avg_tf = np.mean([count for _, count in bow]) if bow else 1\n",
        "    return [(term_id, 1 + math.log(count / avg_tf) if count > 0 else 0) for term_id, count in bow]\n",
        "\n",
        "def compute_logarithmic_tf(tokens, dictionary):\n",
        "    bow = dictionary.doc2bow(tokens)\n",
        "    return [(term_id, 1 + math.log(count) if count > 0 else 0) for term_id, count in bow]\n",
        "\n",
        "# Custom IDF methods\n",
        "def compute_standard_idf(df, N):\n",
        "    return {term: math.log(N / (df.get(term, 1))) for term in df}\n",
        "\n",
        "def compute_probabilistic_idf(df, N):\n",
        "    return {term: math.log((N - df.get(term, 0)) / (df.get(term, 1))) for term in df}\n",
        "\n",
        "def compute_none_idf(df, N):\n",
        "    return {term: 1 for term in df}\n",
        "\n",
        "# Custom normalization methods\n",
        "def apply_normalization(vector, norm_method, doc_length=None):\n",
        "    if not vector:\n",
        "        return vector\n",
        "    if norm_method == 'cosine':\n",
        "        norm = np.sqrt(sum(weight ** 2 for _, weight in vector))\n",
        "        return [(term_id, weight / norm if norm != 0 else weight) for term_id, weight in vector]\n",
        "    elif norm_method == 'pivoted':\n",
        "        pivot = 0.3\n",
        "        norm = sum(weight for _, weight in vector)\n",
        "        return [(term_id, weight * (1 - pivot + pivot * doc_length / norm) if norm != 0 else weight) \n",
        "                for term_id, weight in vector]\n",
        "    elif norm_method == 'byte':\n",
        "        norm = doc_length if doc_length and doc_length > 0 else 1\n",
        "        return [(term_id, weight / norm) for term_id, weight in vector]\n",
        "    return vector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compute TF-IDF Vectors\n",
        "Compute TF-IDF vectors for documents and queries using custom TF, IDF, and normalization methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_tfidf_gensim(docs, queries, tf_method_name, idf_method_name, norm_method):\n",
        "    doc_tokens = [tokenize(doc) for doc in docs.values()]\n",
        "    query_tokens = {qid: tokenize(query) for qid, query in queries.items()}\n",
        "    doc_lengths = [len(tokens) for tokens in doc_tokens]\n",
        "    \n",
        "    dictionary = corpora.Dictionary(doc_tokens)\n",
        "    \n",
        "    df = defaultdict(int)\n",
        "    for tokens in doc_tokens:\n",
        "        for term in set(tokens):\n",
        "            df[term] += 1\n",
        "    \n",
        "    tf_methods = {\n",
        "        'natural': compute_natural_tf,\n",
        "        'augmented': compute_augmented_tf,\n",
        "        'boolean': compute_boolean_tf,\n",
        "        'log_avg': compute_log_avg_tf,\n",
        "        'logarithmic': compute_logarithmic_tf\n",
        "    }\n",
        "    tf_method = tf_methods[tf_method_name]\n",
        "    \n",
        "    corpus = [tf_method(tokens, dictionary) for tokens in doc_tokens]\n",
        "    \n",
        "    idf_methods = {\n",
        "        'standard': compute_standard_idf,\n",
        "        'probabilistic': compute_probabilistic_idf,\n",
        "        'none': compute_none_idf\n",
        "    }\n",
        "    idf_method = idf_methods[idf_method_name]\n",
        "    N = len(docs)\n",
        "    idf = idf_method(df, N)\n",
        "    \n",
        "    doc_vectors = []\n",
        "    for i, bow in enumerate(corpus):\n",
        "        tfidf_vec = [(term_id, weight * idf.get(dictionary[term_id], 0)) for term_id, weight in bow]\n",
        "        tfidf_vec = apply_normalization(tfidf_vec, norm_method, doc_lengths[i])\n",
        "        doc_vectors.append((list(docs.keys())[i], tfidf_vec))\n",
        "    \n",
        "    query_vectors = {}\n",
        "    for qid, tokens in query_tokens.items():\n",
        "        q_bow = tf_method(tokens, dictionary)\n",
        "        q_tfidf = [(term_id, weight * idf.get(dictionary[term_id], 0)) for term_id, weight in q_bow]\n",
        "        q_tfidf = apply_normalization(q_tfidf, norm_method, len(tokens))\n",
        "        query_vectors[qid] = q_tfidf\n",
        "    \n",
        "    return doc_vectors, query_vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluate Metrics\n",
        "Evaluate the system using Precision@10, Recall, and MAP for each query, using dot product for similarity to preserve normalization effects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_metrics_gensim(doc_vectors, query_vector, qrels, k=10):\n",
        "    k = min(k, len(doc_vectors))\n",
        "    similarities = []\n",
        "    for doc_id, doc_vec in doc_vectors:\n",
        "        doc_vec_dict = {term_id: weight for term_id, weight in doc_vec}\n",
        "        query_vec_dict = {term_id: weight for term_id, weight in query_vector}\n",
        "        dot_product = sum(doc_vec_dict.get(term_id, 0) * query_vec_dict.get(term_id, 0) \n",
        "                         for term_id in set(doc_vec_dict) & set(query_vec_dict))\n",
        "        similarity = dot_product  # Use dot product to preserve normalization effects\n",
        "        similarities.append((doc_id, similarity))\n",
        "    \n",
        "    # Sort documents by similarity (descending)\n",
        "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
        "    top_k_ids = [doc_id for doc_id, _ in similarities[:k]]\n",
        "    \n",
        "    # Compute Precision@10 and Recall\n",
        "    top_k_relevant = np.array([1 if did in qrels else 0 for did in top_k_ids])\n",
        "    precision_at_k = np.mean(top_k_relevant) if k else 0.0\n",
        "    recall = np.sum(top_k_relevant) / len(qrels) if len(qrels) else 0.0\n",
        "    \n",
        "    # Compute Average Precision (AP)\n",
        "    ap = 0.0\n",
        "    if len(qrels) > 0:\n",
        "        relevant_count = 0\n",
        "        precision_sum = 0.0\n",
        "        for rank, doc_id in enumerate(top_k_ids, 1):\n",
        "            if doc_id in qrels:\n",
        "                relevant_count += 1\n",
        "                precision = relevant_count / rank\n",
        "                precision_sum += precision\n",
        "        ap = precision_sum / len(qrels) if relevant_count > 0 else 0.0\n",
        "    \n",
        "    return {'Precision@10': precision_at_k, 'Recall': recall, 'MAP': ap}\n",
        "\n",
        "def evaluate_collection_gensim(docs, queries, qrels, tf_method, idf_method, norm_method):\n",
        "    doc_vectors, query_vectors = compute_tfidf_gensim(docs, queries, tf_method, idf_method, norm_method)\n",
        "    results = Parallel(n_jobs=-1)(delayed(evaluate_metrics_gensim)(\n",
        "        doc_vectors, query_vectors[qid], qrels[qid], k=10) for qid in queries)\n",
        "    return {\n",
        "        'Precision@10': np.mean([r['Precision@10'] for r in results]),\n",
        "        'Recall': np.mean([r['Recall'] for r in results]),\n",
        "        'MAP': np.mean([r['MAP'] for r in results])\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Main Execution\n",
        "Evaluate all combinations of TF, IDF, and normalization methods on the datasets and save results to a CSV file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing MED...\n",
            "Processing CISI...\n",
            "Processing cran...\n",
            "Processing npl...\n",
            "Results saved to ./collections/tfidf_results_gensim.csv\n"
          ]
        }
      ],
      "source": [
        "tf_methods = {\n",
        "    'natural': compute_natural_tf,\n",
        "    'augmented': compute_augmented_tf,\n",
        "    'boolean': compute_boolean_tf,\n",
        "    'log_avg': compute_log_avg_tf,\n",
        "    'logarithmic': compute_logarithmic_tf\n",
        "}\n",
        "idf_methods = {\n",
        "    'standard': compute_standard_idf,\n",
        "    'probabilistic': compute_probabilistic_idf,\n",
        "    'none': compute_none_idf\n",
        "}\n",
        "norm_methods = [None, 'cosine', 'pivoted', 'byte']\n",
        "datasets = ['MED','CISI', 'cran', 'npl']\n",
        "base_path = '../data/processed'\n",
        "\n",
        "all_results = []\n",
        "for dataset in datasets:\n",
        "    print(f\"Processing {dataset}...\")\n",
        "    docs, queries, qrels = load_collection(base_path, dataset)\n",
        "    if not docs or not queries or not qrels:\n",
        "        continue\n",
        "    combinations = list(product(tf_methods.keys(), idf_methods.keys(), norm_methods))\n",
        "    results = Parallel(n_jobs=-1)(delayed(evaluate_collection_gensim)(\n",
        "        docs, queries, qrels, tf_m, idf_m, norm_m) for tf_m, idf_m, norm_m in combinations)\n",
        "    all_results.extend(zip([dataset]*len(results), \n",
        "                          [tf_m for tf_m, _, _ in combinations], \n",
        "                          [idf_m for _, idf_m, _ in combinations], \n",
        "                          [norm_m if norm_m else 'none' for _, _, norm_m in combinations], \n",
        "                          results))\n",
        "\n",
        "results_df = pd.DataFrame([(d, tf, idf, n, r['Precision@10'], r['Recall'], r['MAP']) \n",
        "                          for d, tf, idf, n, r in all_results],\n",
        "                          columns=['Dataset', 'TF', 'IDF', 'Norm', 'Precision@10', 'Recall', 'MAP'])\n",
        "results_df.to_csv(f'../tfidf_results_gensim.csv', index=False)\n",
        "print(f\"Results saved to ../tfidf_results_gensim.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Display Best Configurations\n",
        "Display the best TF, IDF, and normalization combination for each dataset and the overall best combination across all datasets based on MAP."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Best Configurations for Each Dataset:\n",
            "\n",
            "Table of Best Configurations for Each Dataset:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dataset</th>\n",
              "      <th>TF</th>\n",
              "      <th>IDF</th>\n",
              "      <th>Norm</th>\n",
              "      <th>MAP</th>\n",
              "      <th>Precision@10</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MED</td>\n",
              "      <td>logarithmic</td>\n",
              "      <td>standard</td>\n",
              "      <td>cosine</td>\n",
              "      <td>0.264143</td>\n",
              "      <td>0.650000</td>\n",
              "      <td>0.319586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CISI</td>\n",
              "      <td>logarithmic</td>\n",
              "      <td>standard</td>\n",
              "      <td>cosine</td>\n",
              "      <td>0.059436</td>\n",
              "      <td>0.206250</td>\n",
              "      <td>0.081888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cran</td>\n",
              "      <td>boolean</td>\n",
              "      <td>standard</td>\n",
              "      <td>pivoted</td>\n",
              "      <td>0.002599</td>\n",
              "      <td>0.008000</td>\n",
              "      <td>0.006137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>npl</td>\n",
              "      <td>augmented</td>\n",
              "      <td>standard</td>\n",
              "      <td>pivoted</td>\n",
              "      <td>0.132711</td>\n",
              "      <td>0.317204</td>\n",
              "      <td>0.192412</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Dataset           TF       IDF     Norm       MAP  Precision@10    Recall\n",
              "0     MED  logarithmic  standard   cosine  0.264143      0.650000  0.319586\n",
              "1    CISI  logarithmic  standard   cosine  0.059436      0.206250  0.081888\n",
              "2    cran      boolean  standard  pivoted  0.002599      0.008000  0.006137\n",
              "3     npl    augmented  standard  pivoted  0.132711      0.317204  0.192412"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Best Configuration for all Dataset:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TF</th>\n",
              "      <th>IDF</th>\n",
              "      <th>Norm</th>\n",
              "      <th>MAP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>logarithmic</td>\n",
              "      <td>probabilistic</td>\n",
              "      <td>pivoted</td>\n",
              "      <td>0.108332</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            TF            IDF     Norm       MAP\n",
              "0  logarithmic  probabilistic  pivoted  0.108332"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Part 1: Best configuration for each dataset\n",
        "print(\"\\nBest Configurations for Each Dataset:\")\n",
        "best_configs = []\n",
        "for dataset in datasets:\n",
        "    subset = results_df[results_df['Dataset'] == dataset]\n",
        "    if not subset.empty:\n",
        "        best = subset.loc[subset['MAP'].idxmax()]\n",
        "        best_configs.append({\n",
        "            'Dataset': dataset,\n",
        "            'TF': best['TF'],\n",
        "            'IDF': best['IDF'],\n",
        "            'Norm': best['Norm'],\n",
        "            'MAP': best['MAP'],\n",
        "            'Precision@10': best['Precision@10'],\n",
        "            'Recall': best['Recall']\n",
        "        })\n",
        "        \n",
        "# Display as a table\n",
        "best_configs_df = pd.DataFrame(best_configs)\n",
        "print(\"\\nTable of Best Configurations for Each Dataset:\")\n",
        "display(best_configs_df)\n",
        "\n",
        "best_config_all = []\n",
        "# Part 2: Overall best configuration across all datasets\n",
        "if not results_df.empty:\n",
        "    # Calculate mean MAP for each combination of TF, IDF, and Norm across all datasets\n",
        "    overall_best = results_df.groupby(['TF', 'IDF', 'Norm'])['MAP'].mean().reset_index()\n",
        "    best_comb = overall_best.loc[overall_best['MAP'].idxmax()]\n",
        "    best_config_all.append({\n",
        "            'TF': best_comb['TF'],\n",
        "            'IDF': best_comb['IDF'],\n",
        "            'Norm': best_comb['Norm'],\n",
        "            'MAP': best_comb['MAP'],})\n",
        "    best_config_all_df = pd.DataFrame(best_config_all)\n",
        "    print(f\"\\nBest Configuration for all Dataset:\")\n",
        "    display(best_config_all_df)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
